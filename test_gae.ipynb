{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('disser': conda)"
  },
  "interpreter": {
   "hash": "de4a326d1af7be3981cb728d2c4eed6e24675e020b4ba825e6ef7b2ba986d345"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/dcs/pg20/u2085214/fc/learn-to-cluster\n",
      "Traceback (most recent call last):\n",
      "  File \"lgcn/main.py\", line 4, in <module>\n",
      "    import torch\n",
      "ImportError: No module named torch\n",
      "Traceback (most recent call last):\n",
      "  File \"lgcn/main.py\", line 4, in <module>\n",
      "    import torch\n",
      "ImportError: No module named torch\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!sh 'scripts/lgcn/train_lgcn_ms1m.sh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from mmcv import Config\n",
    "\n",
    "import sys\n",
    "from utils import (create_logger, set_random_seed, rm_suffix,\n",
    "                   mkdir_if_no_exists)\n",
    "\n",
    "from gae.models import build_model\n",
    "from gae import build_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda available: False\n"
     ]
    }
   ],
   "source": [
    "cfg_name = 'cfg_train_gae_cut.py'\n",
    "config='./gae/configs/cfg_train_gae_cut.py' # written in script \n",
    "cfg = Config.fromfile(config)\n",
    "cfg.cuda = torch.cuda.is_available()\n",
    "print('cuda available:',cfg.cuda)\n",
    "\n",
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "if cfg.get('cudnn_deterministic', False):\n",
    "    torch.backends.cudnn.deterministic = Trueprint(cfg.cuda)\n",
    "\n",
    "setattr(cfg,'work_dir','./data/work_dir/'+cfg_name)\n",
    "mkdir_if_no_exists(cfg.work_dir, is_folder=True)\n",
    "\n",
    "cfg.phase = 'train' # written in script\n",
    "\n",
    "cfg.load_from = None\n",
    "cfg.resume_from = None\n",
    "\n",
    "cfg.gpus = 1\n",
    "cfg.distributed = False\n",
    "cfg.save_output = False\n",
    "cfg.no_cuda = False\n",
    "cfg.force = False\n",
    "\n",
    "cfg.seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-07-06 05:17:00,993] Set random seed to 1\n",
      "[2021-07-06 05:17:00,993] Set random seed to 1\n",
      "[2021-07-06 05:17:00,993] Set random seed to 1\n",
      "[2021-07-06 05:17:00,993] Set random seed to 1\n",
      "2021-07-06 05:17:00,993 - INFO - Set random seed to 1\n"
     ]
    }
   ],
   "source": [
    "logger = create_logger()\n",
    "\n",
    "if cfg.seed is not None:\n",
    "    logger.info('Set random seed to {}'.format(cfg.seed))\n",
    "    set_random_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg.model['type'], **cfg.model['kwargs']) #build model: odel = dict(type='gae', kwargs=dict(feature_dim=256))\n",
    "handler = build_handler(cfg.phase) #tain_gae.py or test_gae.py <= args.pahse:choices=['test', 'train']\n",
    "\n",
    "# handler(model, cfg, logger) #e.g. call train_gae(gae,cfg,tracking event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from mmcv.runner import Runner, obj_from_dict\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from gae.datasets import build_dataset, build_dataloader\n",
    "from gae.online_evaluation import online_evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[./data/labels/part0_train_cut.meta] #cls: 4, #inst: 300\n[Time] read meta and feature consumes 0.0043 s\n[Time] read knn graph consumes 0.0095 s\nfeature shape: (300, 256), norm_feat: True, sort_knns: True k_at_hop: [40, 5], active_connection: 10\nlabels shape: (300,)\nknns_graph shape: (300, 80)\n"
     ]
    }
   ],
   "source": [
    "for k, v in cfg.model['kwargs'].items(): #kwargs=dict(feature_dim=256)\n",
    "    setattr(cfg.train_data, k, v) #k? v?\n",
    "dataset = build_dataset(cfg.train_data)\n",
    "\n",
    "data_loaders = [build_dataloader(dataset,\n",
    "                        cfg.batch_size_per_gpu,\n",
    "                        cfg.workers_per_gpu,\n",
    "                        train=True,\n",
    "                        shuffle=True)]\n",
    "\n",
    "if cfg.distributed:\n",
    "    raise NotImplementedError\n",
    "#call _single_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_single_train\n",
    "if cfg.gpus > 1:\n",
    "    raise NotImplemented\n",
    "\n",
    "# model = MMDataParallel(model, device_ids=range(cfg.gpus))#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(model, optimizer_cfg):\n",
    "    \"\"\"Build optimizer from configs.\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'module'):\n",
    "        model = model.module\n",
    "\n",
    "    optimizer_cfg = optimizer_cfg.copy() #dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "    paramwise_options = optimizer_cfg.pop('paramwise_options', None)\n",
    "    assert paramwise_options is None\n",
    "    return obj_from_dict(optimizer_cfg, torch.optim,\n",
    "                         dict(params=model.parameters())) \n",
    "\n",
    "    \"\"\"\n",
    "    obj_from_dict(info, parent=None, default_args=None)\n",
    "\n",
    "    Args:\n",
    "        info (dict): Object types and arguments.\n",
    "        parent (:class:`module`): Module which may containing expected object\n",
    "            classes.\n",
    "        default_args (dict, optional): Default arguments for initializing the\n",
    "            object.\n",
    "\n",
    "    Returns:\n",
    "      any type: Object built from the dict.\n",
    "      return obj_type(**args) \n",
    "      e.g. SGD(lr=0.01, momentum=0.9, weight_decay=1e-4, ...)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = build_optimizer(model, cfg.optimizer) #look at the func above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_processor(model, data, train_mode):\n",
    "    assert train_mode\n",
    "\n",
    "    A_pred, loss = model(data, return_loss=True) #retrn_loss=true => output with loss \n",
    "    log_vars = OrderedDict()\n",
    "    \n",
    "    _, A, _, gtmat = data\n",
    "    \n",
    "    print('[shape] A_pred={} A={}'.format(A_pred.shape, A.shape))\n",
    "    \n",
    "    acc, p, r = online_evaluate(A_pred, A)\n",
    "    \n",
    "    log_vars['loss'] = loss.item()\n",
    "    log_vars['accuracy'] = acc\n",
    "    log_vars['precision'] = p\n",
    "    log_vars['recall'] = r\n",
    "\n",
    "    outputs = dict(loss=loss, log_vars=log_vars, num_samples=len(gtmat))\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _single_train(model, data_loaders, cfg): #called from train_gae\n",
    "    if cfg.gpus > 1:\n",
    "        raise NotImplemented\n",
    "    # put model on gpus\n",
    "    \n",
    "    # model = MMDataParallel(model, device_ids=range(cfg.gpus)).cuda() \n",
    "    # build runner\n",
    "    optimizer = build_optimizer(model, cfg.optimizer) #look at the func above\n",
    "\n",
    "    runner = Runner(model, batch_processor, optimizer, cfg.work_dir,\n",
    "                    cfg.log_level) #work_dir from --work_dir argument\n",
    "    runner.register_training_hooks(cfg.lr_config, cfg.optimizer_config,\n",
    "                                   cfg.checkpoint_config, cfg.log_config)#present related results\n",
    "\n",
    "    if cfg.resume_from:\n",
    "        runner.resume(cfg.resume_from)\n",
    "    elif cfg.load_from:\n",
    "        runner.load_checkpoint(cfg.load_from)\n",
    "    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)\n",
    "\n",
    "\n",
    "# if cfg.resume_from:\n",
    "#     runner.resume(cfg.resume_from)\n",
    "# elif cfg.load_from:\n",
    "#     runner.load_checkpoint(cfg.load_from)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-90121d55e8e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0m_single_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-93a3140502f3>\u001b[0m in \u001b[0;36m_single_train\u001b[0;34m(model, data_loaders, cfg)\u001b[0m\n\u001b[1;32m     10\u001b[0m     runner = Runner(model, batch_processor, optimizer, cfg.work_dir,\n\u001b[1;32m     11\u001b[0m                     cfg.log_level) #work_dir from --work_dir argument\n\u001b[0;32m---> 12\u001b[0;31m     runner.register_training_hooks(cfg.lr_config, cfg.optimizer_config,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                    cfg.checkpoint_config, cfg.log_config)#present related results\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mmcv/runner/runner.py\u001b[0m in \u001b[0;36mregister_training_hooks\u001b[0;34m(self, lr_config, optimizer_config, checkpoint_config, log_config)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mLoggerHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \"\"\"\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_lr_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_optimizer_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_checkpoint_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mmcv/runner/runner.py\u001b[0m in \u001b[0;36mregister_lr_hook\u001b[0;34m(self, lr_config)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_lr_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;34m'policy'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlr_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mhook_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'policy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'LrUpdaterHook'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mlr_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if cfg.distributed:\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    _single_train(model, data_loaders, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}